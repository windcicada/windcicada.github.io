<!DOCTYPE html>
<html lang="en"></html>
    <style type="text/css">
    	.fireworks {
    		position: fixed;
    		pointer-events: none;
    		top: 0;
    		left: 0;
    		height: 100%;
    	}
    </style>
    <canvas class="fireworks"></canvas>
    <script src="/js/anime.min.js"></script>
    <script src="/js/fireworks.js"></script>
    <script type="text/javascript">
        fireworks.setCanvasSize();
    </script>


    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Ascend C算子 学习笔记 - Dong</title><meta name="Description" content="Dong"><meta property="og:url" content="https://wangyudong.netlify.app/huaweishengteng/">
  <meta property="og:site_name" content="Dong">
  <meta property="og:title" content="Ascend C算子 学习笔记">
  <meta property="og:description" content="Ascend及算子开发知识整理 昇腾计算产业生态 昇腾计算软硬件体系: 应用层: 包括ModelArts、HiAI Service、Mindx等平台。">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-11T10:50:00+08:00">
    <meta property="article:modified_time" content="2024-07-11T10:50:00+08:00">
    <meta property="article:tag" content="Website">
    <meta property="og:image" content="https://wangyudong.netlify.app/images/avatar.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://wangyudong.netlify.app/images/avatar.png">
  <meta name="twitter:title" content="Ascend C算子 学习笔记">
  <meta name="twitter:description" content="Ascend及算子开发知识整理 昇腾计算产业生态 昇腾计算软硬件体系: 应用层: 包括ModelArts、HiAI Service、Mindx等平台。">
<meta name="application-name" content="Dong">
<meta name="apple-mobile-web-app-title" content="Dong"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://wangyudong.netlify.app/huaweishengteng/" /><link rel="prev" href="https://wangyudong.netlify.app/awards/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Ascend C算子 学习笔记",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/wangyudong.netlify.app\/huaweishengteng\/"
        },"genre": "posts","keywords": "website","wordcount":  6825 ,
        "url": "https:\/\/wangyudong.netlify.app\/huaweishengteng\/","datePublished": "2024-07-11T10:50:00+08:00","dateModified": "2024-07-11T10:50:00+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Dong"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('light' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'light' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><!DOCTYPE html><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Dong"></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> Dong <i class='fa fa-heart'></i>
                    </a><a class="menu-item" href="/posts/"> 文章 
                    </a><a class="menu-item" href="/tags/"> 标签 
                    </a><a class="menu-item" href="/categories/"> 分类 
                    </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Dong"></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/"> Dong <i class='fa fa-heart'></i>
                </a><a class="menu-item" href="/posts/"> 文章 
                </a><a class="menu-item" href="/tags/"> 标签 
                </a><a class="menu-item" href="/categories/"> 分类 
                </a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Ascend C算子 学习笔记</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Dong</a></span>&nbsp;<span class="post-category">included in <a href="/categories/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/"><i class="far fa-folder fa-fw"></i>工作日志</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2024-07-11">2024-07-11</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;6825 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;14 minutes&nbsp;<span id="/huaweishengteng/" class="leancloud_visitors" data-flag-title="Ascend C算子 学习笔记">
                        <i class="far fa-eye fa-fw"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;views
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#昇腾计算产业生态">昇腾计算产业生态</a>
      <ul>
        <li>
          <ul>
            <li><a href="#昇腾计算软硬件体系">昇腾计算软硬件体系:</a></li>
            <li><a href="#合作伙伴">合作伙伴:</a></li>
            <li><a href="#行业应用">行业应用:</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#orange-pi-ai-pro">Orange Pi AI Pro</a>
      <ul>
        <li>
          <ul>
            <li><a href="#主要特点">主要特点</a></li>
            <li><a href="#应用场景">应用场景</a></li>
            <li><a href="#开发板规格">开发板规格</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#什么是算子">什么是算子</a>
      <ul>
        <li><a href="#算子基本概念">算子基本概念</a></li>
      </ul>
    </li>
    <li><a href="#ascend-c算子">Ascend C算子</a>
      <ul>
        <li><a href="#术语解释">术语解释</a></li>
        <li><a href="#cann优化手段">CANN优化手段</a></li>
        <li><a href="#编程模型spmd模型">编程模型：SPMD模型</a></li>
        <li><a href="#ascend算子的优势">Ascend算子的优势</a></li>
        <li><a href="#ascend-c算子开发流程">Ascend C算子开发流程</a></li>
        <li><a href="#核函数示例">核函数示例</a></li>
        <li><a href="#调用核函数">调用核函数</a></li>
      </ul>
    </li>
    <li><a href="#算子开发示例sinh算子">算子开发示例：Sinh算子</a>
      <ul>
        <li><a href="#addcustom-目录结构">AddCustom 目录结构</a></li>
        <li><a href="#sinh算子开发流程">Sinh算子开发流程</a></li>
        <li><a href="#sinh算子功能">Sinh算子功能</a></li>
        <li><a href="#算子实现流程">算子实现流程</a>
          <ul>
            <li>
              <ul>
                <li><a href="#op_hostsinh_custom_tilingh"><code>op_host/sinh_custom_tiling.h</code></a></li>
                <li><a href="#op_hostsinh_customcpp"><code>op_host/sinh_custom.cpp</code></a></li>
                <li><a href="#op_kernelsinh_customcpp"><code>op_kernel/sinh_custom.cpp</code></a></li>
              </ul>
            </li>
            <li><a href="#算子编译部署">算子编译部署</a></li>
            <li><a href="#算子测试">算子测试</a>
              <ul>
                <li><a href="#scriptsgen_datapy"><code>scripts/gen_data.py</code></a></li>
                <li><a href="#srcmaincpp"><code>src/main.cpp</code></a></li>
                <li><a href="#srcop_runnercpp"><code>src/op_runner.cpp</code></a></li>
              </ul>
            </li>
          </ul>
        </li>
        <li><a href="#对部署的算子进行测试">对部署的算子进行测试</a></li>
        <li><a href="#过程注意点">过程注意点</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="../images/Ascend/Ascend.png"
        data-srcset="../images/Ascend/Ascend.png, ../images/Ascend/Ascend.png 1.5x, ../images/Ascend/Ascend.png 2x"
        data-sizes="auto"
        alt="../images/Ascend/Ascend.png"
        title="Ascend" /></p>
<h1 id="ascend及算子开发知识整理">Ascend及算子开发知识整理</h1>
<h2 id="昇腾计算产业生态">昇腾计算产业生态</h2>
<h4 id="昇腾计算软硬件体系">昇腾计算软硬件体系:</h4>
<ul>
<li><strong>应用层</strong>: 包括ModelArts、HiAI Service、Mindx等平台。</li>
<li><strong>框架层</strong>: 包括MindSpore、TensorFlow、PyTorch等。</li>
<li><strong>计算架构层</strong>: 异算计算架构CANN和NPU驱动。</li>
<li><strong>硬件层</strong>: 系列硬件和昇腾系列处理器。</li>
</ul>
<h4 id="合作伙伴">合作伙伴:</h4>
<ul>
<li><strong>IHV（独立硬件供应商）</strong></li>
<li><strong>高校</strong>: 教学科研、算子众筹。</li>
<li><strong>开发者</strong>: 算子贡献、开源贡献。</li>
<li><strong>ISV（独立软件供应商）</strong></li>
<li><strong>OEM/ODM</strong>: 产品销售、开源开放。</li>
</ul>
<h4 id="行业应用">行业应用:</h4>
<p>​	广泛应用于医疗、运营商、能源、交通、互联网、制造、金融、机器人等领域。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="../images/Ascend/AscendProd.png"
        data-srcset="../images/Ascend/AscendProd.png, ../images/Ascend/AscendProd.png 1.5x, ../images/Ascend/AscendProd.png 2x"
        data-sizes="auto"
        alt="../images/Ascend/AscendProd.png"
        title="Ascend" /></p>
<p>​	昇腾计算产业以“硬件开放，软件开源，使能合作伙伴”的开放生态，推动发展。聚焦计算架构、处理器和基础软件的创新与研发，通过自有硬件和伙伴硬件相结合的方式为客户提供多样化的算力选择。昇腾计算产业发展致力于将AI新技术的红利带到世界的每个角落，让人人充分享受AI带来的美好。在AI治理上，华为与生态、商业伙伴共同倡导向善、包容、普惠和负责任的AI， 为人类社会发展带来价值。</p>
<hr>
<h2 id="orange-pi-ai-pro">Orange Pi AI Pro</h2>
<p><strong>Orange Pi AI Pro</strong>是由香橙派与华为联合打造的一款高性能AI开发板，搭载了华为昇腾（Ascend）AI处理器，具备强大的计算能力和丰富的接口，适用于多种AI应用场景。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="../images/Ascend/orangePi.png"
        data-srcset="../images/Ascend/orangePi.png, ../images/Ascend/orangePi.png 1.5x, ../images/Ascend/orangePi.png 2x"
        data-sizes="auto"
        alt="../images/Ascend/orangePi.png"
        title="Ascend" /></p>
<h4 id="主要特点">主要特点</h4>
<ol>
<li><strong>处理器</strong>：
<ul>
<li>搭载华为Ascend 310B AI处理器，提供高达8 TOPS INT8的计算能力，适用于图像和视频分析、推理计算等任务。</li>
</ul>
</li>
<li><strong>内存</strong>：
<ul>
<li>提供8GB和16GB LPDDR4X-3200内存版本。</li>
</ul>
</li>
<li><strong>存储</strong>：
<ul>
<li>支持M.2 2280插槽，可扩展SATA/NVMe SSD。</li>
<li>提供eMMC 5.1存储选项，容量从32GB到256GB不等。</li>
<li>具有TF卡插槽。</li>
</ul>
</li>
<li><strong>连接性</strong>：
<ul>
<li>支持Wi-Fi 5和Bluetooth 4.2。</li>
<li>千兆以太网接口。</li>
</ul>
</li>
<li><strong>视频输出</strong>：
<ul>
<li>两个HDMI 2.0接口，支持4K@60FPS输出。</li>
<li>一个MIPI DSI接口。</li>
</ul>
</li>
<li><strong>摄像头接口</strong>：
<ul>
<li>两个MIPI摄像头接口，兼容Raspberry Pi Camera模块。</li>
</ul>
</li>
<li><strong>其他接口</strong>：
<ul>
<li>两个USB 3.0 Type-A接口。</li>
<li>一个USB 3.0 Type-C接口。</li>
<li>一个USB Type-C 20V电源接口。</li>
<li>40针GPIO接口，支持GPIO、UART、I2C、SPI、I2S、PWM等。</li>
</ul>
</li>
<li><strong>操作系统支持</strong>：
<ul>
<li>支持Ubuntu和openEuler操作系统。</li>
</ul>
</li>
</ol>
<h4 id="应用场景">应用场景</h4>
<ul>
<li><strong>教育</strong>：为学生和研究人员提供一个高性能的AI开发平台。</li>
<li><strong>机器人</strong>：支持复杂的图像和视频处理，适用于自动导航和环境感知。</li>
<li><strong>无人机</strong>：提供强大的计算能力，支持实时图像处理和飞行控制。</li>
</ul>
<h4 id="开发板规格">开发板规格</h4>
<ul>
<li>尺寸：107 x 68 mm。</li>
<li>提供丰富的外围接口，增强开发板的扩展性和适用性。</li>
</ul>
<hr>
<h2 id="什么是算子">什么是算子</h2>
<ul>
<li><strong>计算逻辑</strong>: 对应网络中层或节点的计算逻辑。</li>
<li><strong>数学含义</strong>: 一个函数空间到另一个函数空间的映射。</li>
<li><strong>常见举例</strong>: tanh、ReLu、sigmoid等。</li>
</ul>
<h3 id="算子基本概念">算子基本概念</h3>
<ul>
<li><strong>算子名称</strong>: 用于标志网络中的某个算子。</li>
<li><strong>算子类型</strong>: 根据算子类型实现算子的具体匹配。</li>
<li><strong>数据容器</strong>:
<ul>
<li><strong>Tensor</strong>: 存储算子输入输出数据的容器，包含name、shape、dtype和format等属性。</li>
<li><strong>属性</strong>: 如axis表示张量的维度。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="ascend-c算子">Ascend C算子</h2>
<p>Ascend C算子采用标准C++语法和一组类库API进行编程，方便根据需求选择合适的API开发自定义算子。Ascend C算子用于高性能矩阵计算，特别适合AI运算中的矩阵计算任务。</p>
<h3 id="术语解释">术语解释</h3>
<ul>
<li><strong>4核CPU</strong>: 负责逻辑控制。</li>
<li><strong>NPU</strong>: 专用于计算任务。</li>
<li><strong>HBM类显存</strong>: 高带宽存储器，提供快速数据访问。</li>
<li><strong>标量逻辑控制</strong>: 控制单一数据的运算。</li>
<li><strong>AICPU算子开发</strong>: 在AI处理器上进行算子开发。</li>
<li><strong>向量矩阵计算</strong>: Ascend C支持高效的向量和矩阵运算。</li>
<li><strong>CANN</strong>: 使能并行加速和高效开发的框架，融合了GPU和NPU的优势，提供高效的自研算子。</li>
</ul>
<h3 id="cann优化手段">CANN优化手段</h3>
<ul>
<li><strong>数据优化</strong>: 数据融合、流水线处理和GE（Graph Engine）。</li>
<li><strong>计算优化</strong>: 动态Shape支持、Transformer加速库、深度融合算子。</li>
<li><strong>通讯优化</strong>: 数据搬移（HCCL），整图下沉，自适应梯度切分。</li>
<li><strong>模型瘦身</strong>: 通过AMCT工具进行模型压缩。</li>
<li><strong>图像预处理</strong>: 使用DVPP进行图像裁剪和归一化处理。</li>
</ul>
<h3 id="编程模型spmd模型">编程模型：SPMD模型</h3>
<p>Ascend C算子编程采用SPMD（Single-Program Multiple-Data）编程模型。SPMD是一种常用的并行计算方法，是提高计算速度的有效手段。</p>
<ul>
<li>
<p><strong>SPMD简介</strong></p>
<p>在SPMD模型中，从输入数据到输出数据通常需要经过多个阶段的任务处理（例如，T1、T2、T3）。SPMD会启动一组进程，并行处理待处理的数据。具体来说，待处理的数据被切分成多个分片，然后分发给不同的进程，每个进程对自己的数据分片依次进行各个任务的处理。</p>
</li>
<li>
<p><strong>Ascend C中的SPMD应用</strong></p>
<p>在Ascend C编程模型中，待处理的数据被拆分并同时在多个计算核心（类似于多个进程）上运行，从而实现更高的性能。多个AI Core共享相同的指令代码，每个核上的运行实例唯一的区别是<code>block_idx</code>不同，每个核通过不同的<code>block_idx</code>来识别自己的身份。<code>block</code>的概念类似于进程，而<code>block_idx</code>则类似于进程ID。下面是并行计算过程的示意图：</p>
</li>
</ul>
<div class="mermaid" id="id-1"></div>
<h3 id="ascend算子的优势">Ascend算子的优势</h3>
<ul>
<li><strong>编程语言</strong>: 使用C/C++语言。</li>
<li><strong>屏蔽硬件差异</strong>: 编程模型屏蔽硬件差异。</li>
<li><strong>类库API封装</strong>: 提供封装好的类库API。</li>
<li><strong>孪生调试</strong>: 可以在CPU侧模拟NPU侧行为。</li>
</ul>
<h3 id="ascend-c算子开发流程">Ascend C算子开发流程</h3>
<ol>
<li><strong>掌握Ascend C算子的核函数开发流程</strong>。</li>
<li><strong>进行简单算子的分析及核函数开发</strong>。</li>
<li><strong>示例</strong>: 使用矢量计算接口进行算子开发，通常分为CopyIn、Compute和CopyOut三步。</li>
</ol>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="../images/Ascend/workflow.png"
        data-srcset="../images/Ascend/workflow.png, ../images/Ascend/workflow.png 1.5x, ../images/Ascend/workflow.png 2x"
        data-sizes="auto"
        alt="../images/Ascend/workflow.png"
        title="Ascend" /></p>
<h3 id="核函数示例">核函数示例</h3>
<p>下面的代码片段取自于Ascend C Add算子的实现代码。算子被调用时，所有的计算核心都执行相同的实现代码，入口函数的入参也是相同的。每个核上处理的数据地址需要在起始地址上增加GetBlockIdx() * BLOCK_LENGTH（每个block处理的数据长度）的偏移来获取。这样实现了多核并行计算的数据切分。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">KernelAdd</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="n">KernelAdd</span><span class="p">()</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">Init</span><span class="p">(</span><span class="n">GM_ADDR</span> <span class="n">x</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">y</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">z</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 获取当前核的起始索引，实现核心并行
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">xGm</span><span class="p">.</span><span class="n">SetGlobalBuffer</span><span class="p">((</span><span class="n">__gm__</span> <span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">x</span> <span class="o">+</span> <span class="n">BLOCK_LENGTH</span> <span class="o">*</span> <span class="n">GetBlockIdx</span><span class="p">(),</span> <span class="n">BLOCK_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">yGm</span><span class="p">.</span><span class="n">SetGlobalBuffer</span><span class="p">((</span><span class="n">__gm__</span> <span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">y</span> <span class="o">+</span> <span class="n">BLOCK_LENGTH</span> <span class="o">*</span> <span class="n">GetBlockIdx</span><span class="p">(),</span> <span class="n">BLOCK_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">zGm</span><span class="p">.</span><span class="n">SetGlobalBuffer</span><span class="p">((</span><span class="n">__gm__</span> <span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">z</span> <span class="o">+</span> <span class="n">BLOCK_LENGTH</span> <span class="o">*</span> <span class="n">GetBlockIdx</span><span class="p">(),</span> <span class="n">BLOCK_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 初始化队列内存，单位为字节
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">pipe</span><span class="p">.</span><span class="n">InitBuffer</span><span class="p">(</span><span class="n">inQueueX</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="p">,</span> <span class="n">TILE_LENGTH</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">half</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="n">pipe</span><span class="p">.</span><span class="n">InitBuffer</span><span class="p">(</span><span class="n">inQueueY</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="p">,</span> <span class="n">TILE_LENGTH</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">half</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="n">pipe</span><span class="p">.</span><span class="n">InitBuffer</span><span class="p">(</span><span class="n">outQueueZ</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="p">,</span> <span class="n">TILE_LENGTH</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">half</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 其他成员函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 实现核函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">extern</span> <span class="s">&#34;C&#34;</span> <span class="n">__global__</span> <span class="n">__aicore__</span> <span class="kt">void</span> <span class="n">add_custom</span><span class="p">(</span><span class="n">GM_ADDR</span> <span class="n">x</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">y</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">z</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 初始化算子类，算子类提供算子初始化和核心处理等方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">KernelAdd</span> <span class="n">op</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 初始化函数，获取该核函数需要处理的输入输出地址，同时完成必要的内存初始化工作
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">op</span><span class="p">.</span><span class="n">Init</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 核心处理函数，完成算子的数据搬运与计算等核心逻辑
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">op</span><span class="p">.</span><span class="n">Process</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>在上述代码中，每个计算核心都执行相同的add_custom函数，但由于GetBlockIdx()的不同，每个核心处理的数据片段也不同。这种方式实现了数据的并行处理，从而提高了计算效率。</p>
<h3 id="调用核函数">调用核函数</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="n">kernel_name</span><span class="o">&lt;&lt;&lt;</span><span class="n">blockDim</span><span class="p">,</span><span class="mi">12</span><span class="n">ctrl</span><span class="p">,</span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">argument</span> <span class="n">list</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>blockDim</strong>: 表示在几个核上运行。</p>
</li>
<li>
<p><strong>12ctrl</strong>: 保留参数，暂设为固定值null。</p>
</li>
<li>
<p><strong>stream</strong>: 任务管理。</p>
</li>
</ul>
<hr>
<h2 id="算子开发示例sinh算子">算子开发示例：Sinh算子</h2>
<h3 id="addcustom-目录结构">AddCustom 目录结构</h3>
<table>
<thead>
<tr>
<th>目录</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>build.sh</code></td>
<td>编译入口脚本</td>
</tr>
<tr>
<td><code>cmake</code></td>
<td>算子工程编译所需脚本及公共编译文件存放目录</td>
</tr>
<tr>
<td>├── <code>config.cmake</code></td>
<td>配置文件</td>
</tr>
<tr>
<td>├── <code>func.cmake</code></td>
<td>功能文件</td>
</tr>
<tr>
<td>├── <code>intf.cmake</code></td>
<td>接口文件</td>
</tr>
<tr>
<td>├── <code>makeself.cmake</code></td>
<td>自我构建文件</td>
</tr>
<tr>
<td>├── <code>util</code></td>
<td>算子工程编译所需脚本及公共编译文件存放目录</td>
</tr>
<tr>
<td><code>CMakeLists.txt</code></td>
<td>算子工程的CMakeLists.txt</td>
</tr>
<tr>
<td><code>CMakePresets.json</code></td>
<td>编译配置项</td>
</tr>
<tr>
<td><code>framework</code></td>
<td>算子插件实现文件目录，单算子模型文件的生成不依赖算子适配插件，无需关注</td>
</tr>
<tr>
<td><code>op_host</code></td>
<td>host侧实现文件</td>
</tr>
<tr>
<td>├── <code>add_custom_tiling.h</code></td>
<td>算子tiling定义文件</td>
</tr>
<tr>
<td>├── <code>add_custom.cpp</code></td>
<td>算子原型注册、shape推导、信息库、tiling实现等内容文件</td>
</tr>
<tr>
<td>├── <code>CMakeLists.txt</code></td>
<td>CMakeLists文件</td>
</tr>
<tr>
<td><code>op_kernel</code></td>
<td>kernel侧实现文件</td>
</tr>
<tr>
<td>├── <code>CMakeLists.txt</code></td>
<td>CMakeLists文件</td>
</tr>
<tr>
<td>├── <code>add_custom.cpp</code></td>
<td>算子代码实现文件</td>
</tr>
<tr>
<td><code>scripts</code></td>
<td>自定义算子工程打包相关脚本所在目录</td>
</tr>
</tbody>
</table>
<h3 id="sinh算子开发流程">Sinh算子开发流程</h3>
<div class="mermaid" id="id-2"></div>
<h3 id="sinh算子功能">Sinh算子功能</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cpp
</span></span><span class="line"><span class="cl">复制代码
</span></span><span class="line"><span class="cl">sinh(x) = (exp(x) - exp(-x)) / 2.0
</span></span></code></pre></td></tr></table>
</div>
</div><p>​	仅处理一个输入，获取一个输出，并且没有任何属性。可参考<code>samples</code>仓中的<code>AddCustom</code>实现进行部分修改即可或者使用<code>msopgen</code>工具生成算子工程文件。</p>
<h3 id="算子实现流程">算子实现流程</h3>
<ol>
<li><strong>生成算子工程</strong>:</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/bin/msopgen gen -i SinhCustom.json -c ai_core-Ascend310B -lan cpp -out Sinh
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>
<p><strong>修改配置文件</strong>:</p>
<p>修改文件<code>CMakePresets.json</code>编译配置项中的<code>ASCEND_CANN_PACKAGE_PATH</code>为<code>/usr/local/Ascend/ascend-toolkit/latest</code>。</p>
</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="s2">&#34;ASCEND_CANN_PACKAGE_PATH&#34;</span><span class="err">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="s2">&#34;PATH&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="nt">&#34;value&#34;</span><span class="p">:</span> <span class="s2">&#34;/usr/local/Ascend/ascend-toolkit/latest&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li><strong>算子实现代码</strong>:</li>
</ol>
<h5 id="op_hostsinh_custom_tilingh"><code>op_host/sinh_custom_tiling.h</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;register/tilingdata_base.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>   
</span></span><span class="line"><span class="cl"><span class="k">namespace</span> <span class="n">optiling</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="n">BEGIN_TILING_DATA_DEF</span><span class="p">(</span><span class="n">SinhCustomTilingData</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">     
</span></span><span class="line"><span class="cl">   <span class="n">TILING_DATA_FIELD_DEF</span><span class="p">(</span><span class="kt">uint32_t</span><span class="p">,</span> <span class="n">totalLength</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">   <span class="n">TILING_DATA_FIELD_DEF</span><span class="p">(</span><span class="kt">uint32_t</span><span class="p">,</span> <span class="n">tileNum</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">END_TILING_DATA_DEF</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl"><span class="n">REGISTER_TILING_DATA_CLASS</span><span class="p">(</span><span class="n">SinhCustom</span><span class="p">,</span> <span class="n">SinhCustomTilingData</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="op_hostsinh_customcpp"><code>op_host/sinh_custom.cpp</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;sinh_custom_tiling.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;register/op_def_registry.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">namespace</span> <span class="n">optiling</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">BLOCK_DIM</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">TILE_NUM</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">static</span> <span class="n">ge</span><span class="o">::</span><span class="n">graphStatus</span> <span class="n">TilingFunc</span><span class="p">(</span><span class="n">gert</span><span class="o">::</span><span class="n">TilingContext</span><span class="o">*</span> <span class="n">context</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">SinhCustomTilingData</span> <span class="n">tiling</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">uint32_t</span> <span class="n">totalLength</span> <span class="o">=</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetInputTensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">GetShapeSize</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">context</span><span class="o">-&gt;</span><span class="n">SetBlockDim</span><span class="p">(</span><span class="n">BLOCK_DIM</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">tiling</span><span class="p">.</span><span class="n">set_totalLength</span><span class="p">(</span><span class="n">totalLength</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">tiling</span><span class="p">.</span><span class="n">set_tileNum</span><span class="p">(</span><span class="n">TILE_NUM</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">tiling</span><span class="p">.</span><span class="n">SaveToBuffer</span><span class="p">(</span><span class="n">context</span><span class="o">-&gt;</span><span class="n">GetRawTilingData</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">GetData</span><span class="p">(),</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetRawTilingData</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">GetCapacity</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetRawTilingData</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">SetDataSize</span><span class="p">(</span><span class="n">tiling</span><span class="p">.</span><span class="n">GetDataSize</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="n">size_t</span> <span class="o">*</span><span class="n">currentWorkspace</span> <span class="o">=</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetWorkspaceSizes</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">currentWorkspace</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ge</span><span class="o">::</span><span class="n">GRAPH_SUCCESS</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">namespace</span> <span class="n">ge</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">static</span> <span class="n">ge</span><span class="o">::</span><span class="n">graphStatus</span> <span class="n">InferShape</span><span class="p">(</span><span class="n">gert</span><span class="o">::</span><span class="n">InferShapeContext</span><span class="o">*</span> <span class="n">context</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">gert</span><span class="o">::</span><span class="n">Shape</span><span class="o">*</span> <span class="n">x1_shape</span> <span class="o">=</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetInputShape</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">gert</span><span class="o">::</span><span class="n">Shape</span><span class="o">*</span> <span class="n">y_shape</span> <span class="o">=</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">GetOutputShape</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="o">*</span><span class="n">y_shape</span> <span class="o">=</span> <span class="o">*</span><span class="n">x1_shape</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">GRAPH_SUCCESS</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">namespace</span> <span class="n">ops</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SinhCustom</span> <span class="o">:</span> <span class="k">public</span> <span class="n">OpDef</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">explicit</span> <span class="n">SinhCustom</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">name</span><span class="p">)</span> <span class="o">:</span> <span class="n">OpDef</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="o">-&gt;</span><span class="n">Input</span><span class="p">(</span><span class="s">&#34;x&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">ParamType</span><span class="p">(</span><span class="n">REQUIRED</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">DataType</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">DT_FLOAT16</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">Format</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">FORMAT_ND</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">UnknownShapeFormat</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">FORMAT_ND</span><span class="p">});</span>
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="o">-&gt;</span><span class="n">Output</span><span class="p">(</span><span class="s">&#34;y&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">ParamType</span><span class="p">(</span><span class="n">REQUIRED</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">DataType</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">DT_FLOAT16</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">Format</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">FORMAT_ND</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">UnknownShapeFormat</span><span class="p">({</span><span class="n">ge</span><span class="o">::</span><span class="n">FORMAT_ND</span><span class="p">});</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="o">-&gt;</span><span class="n">SetInferShape</span><span class="p">(</span><span class="n">ge</span><span class="o">::</span><span class="n">InferShape</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="o">-&gt;</span><span class="n">AICore</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="p">.</span><span class="n">SetTiling</span><span class="p">(</span><span class="n">optiling</span><span class="o">::</span><span class="n">TilingFunc</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="o">-&gt;</span><span class="n">AICore</span><span class="p">().</span><span class="n">AddConfig</span><span class="p">(</span><span class="s">&#34;ascend310b&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">OP_ADD</span><span class="p">(</span><span class="n">SinhCustom</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="op_kernelsinh_customcpp"><code>op_kernel/sinh_custom.cpp</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;kernel_operator.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="k">using</span> <span class="k">namespace</span> <span class="n">AscendC</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">TOTAL_LENGTH</span> <span class="o">=</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">2048</span><span class="p">;</span>                            <span class="c1">// total length of data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">USE_CORE_NUM</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>                                   <span class="c1">// num of core used
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">BLOCK_LENGTH</span> <span class="o">=</span> <span class="n">TOTAL_LENGTH</span> <span class="o">/</span> <span class="n">USE_CORE_NUM</span><span class="p">;</span>         <span class="c1">// length computed of each core
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">TILE_NUM</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>                                       <span class="c1">// split data into 8 tiles for each core
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">BUFFER_NUM</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>                                     <span class="c1">// tensor num for each queue
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">TILE_LENGTH</span> <span class="o">=</span> <span class="n">BLOCK_LENGTH</span> <span class="o">/</span> <span class="n">TILE_NUM</span> <span class="o">/</span> <span class="n">BUFFER_NUM</span><span class="p">;</span> <span class="c1">// seperate to 2 parts, due to double buffer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">KernelSinh</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="n">KernelSinh</span><span class="p">()</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">Init</span><span class="p">(</span><span class="n">GM_ADDR</span> <span class="n">x</span><span class="p">,</span>  <span class="n">GM_ADDR</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="c1">// get start index for current core, core parallel
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    	<span class="n">xGm</span><span class="p">.</span><span class="n">SetGlobalBuffer</span><span class="p">((</span><span class="n">__gm__</span> <span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">x</span> <span class="o">+</span> <span class="n">BLOCK_LENGTH</span> <span class="o">*</span> <span class="n">GetBlockIdx</span><span class="p">(),</span> <span class="n">BLOCK_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    	<span class="n">yGm</span><span class="p">.</span><span class="n">SetGlobalBuffer</span><span class="p">((</span><span class="n">__gm__</span> <span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">y</span> <span class="o">+</span> <span class="n">BLOCK_LENGTH</span> <span class="o">*</span> <span class="n">GetBlockIdx</span><span class="p">(),</span> <span class="n">BLOCK_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    	<span class="c1">// pipe alloc memory to queue, the unit is Bytes
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    	<span class="n">pipe</span><span class="p">.</span><span class="n">InitBuffer</span><span class="p">(</span><span class="n">inQueueX</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="p">,</span> <span class="n">TILE_LENGTH</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">half</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    	<span class="n">pipe</span><span class="p">.</span><span class="n">InitBuffer</span><span class="p">(</span><span class="n">outQueueY</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="p">,</span> <span class="n">TILE_LENGTH</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">half</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">Process</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl"> 	<span class="k">constexpr</span> <span class="kt">int32_t</span> <span class="n">loopCount</span> <span class="o">=</span> <span class="n">TILE_NUM</span> <span class="o">*</span> <span class="n">BUFFER_NUM</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int32_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">loopCount</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">CopyIn</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="n">Compute</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="n">CopyOut</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">CopyIn</span><span class="p">(</span><span class="kt">int32_t</span> <span class="n">progress</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// alloc tensor from queue memory
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">LocalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">xLocal</span> <span class="o">=</span> <span class="n">inQueueX</span><span class="p">.</span><span class="n">AllocTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// copy progress_th tile from global tensor to local tensor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">DataCopy</span><span class="p">(</span><span class="n">xLocal</span><span class="p">,</span> <span class="n">xGm</span><span class="p">[</span><span class="n">progress</span> <span class="o">*</span> <span class="n">TILE_LENGTH</span><span class="p">],</span> <span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// enque input tensors to VECIN queue
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">inQueueX</span><span class="p">.</span><span class="n">EnQue</span><span class="p">(</span><span class="n">xLocal</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">Compute</span><span class="p">(</span><span class="kt">int32_t</span> <span class="n">progress</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// deque input tensors from VECIN queue
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">LocalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">xLocal</span> <span class="o">=</span> <span class="n">inQueueX</span><span class="p">.</span><span class="n">DeQue</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">LocalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">yLocal</span> <span class="o">=</span> <span class="n">outQueueY</span><span class="p">.</span><span class="n">AllocTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// call Add instr for computation
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    
</span></span><span class="line"><span class="cl">        <span class="n">Exp</span><span class="p">(</span><span class="n">xLocal</span><span class="p">,</span><span class="n">xLocal</span><span class="p">,</span><span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">Reciprocal</span><span class="p">(</span><span class="n">yLocal</span><span class="p">,</span><span class="n">xLocal</span><span class="p">,</span><span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">Sub</span><span class="p">(</span><span class="n">yLocal</span><span class="p">,</span> <span class="n">xLocal</span><span class="p">,</span> <span class="n">yLocal</span><span class="p">,</span> <span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">half</span> <span class="n">scalar</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">Muls</span><span class="p">(</span><span class="n">yLocal</span><span class="p">,</span><span class="n">yLocal</span><span class="p">,</span><span class="n">scalar</span><span class="p">,</span><span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// enque the output tensor to VECOUT queue
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">outQueueY</span><span class="p">.</span><span class="n">EnQue</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span><span class="p">(</span><span class="n">yLocal</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// free input tensors for reuse
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">inQueueX</span><span class="p">.</span><span class="n">FreeTensor</span><span class="p">(</span><span class="n">xLocal</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">__aicore__</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">CopyOut</span><span class="p">(</span><span class="kt">int32_t</span> <span class="n">progress</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// deque output tensor from VECOUT queue
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">LocalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">yLocal</span> <span class="o">=</span> <span class="n">outQueueY</span><span class="p">.</span><span class="n">DeQue</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// copy progress_th tile from local tensor to global tensor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">DataCopy</span><span class="p">(</span><span class="n">yGm</span><span class="p">[</span><span class="n">progress</span> <span class="o">*</span> <span class="n">TILE_LENGTH</span><span class="p">],</span> <span class="n">yLocal</span><span class="p">,</span> <span class="n">TILE_LENGTH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// free output tensor for reuse
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">outQueueY</span><span class="p">.</span><span class="n">FreeTensor</span><span class="p">(</span><span class="n">yLocal</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">TPipe</span> <span class="n">pipe</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//create queue for input, in this case depth is equal to buffer num
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">TQue</span><span class="o">&lt;</span><span class="n">QuePosition</span><span class="o">::</span><span class="n">VECIN</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="o">&gt;</span> <span class="n">inQueueX</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//create queue for output, in this case depth is equal to buffer num
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">TQue</span><span class="o">&lt;</span><span class="n">QuePosition</span><span class="o">::</span><span class="n">VECOUT</span><span class="p">,</span> <span class="n">BUFFER_NUM</span><span class="o">&gt;</span> <span class="n">outQueueY</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">GlobalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">xGm</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">GlobalTensor</span><span class="o">&lt;</span><span class="n">half</span><span class="o">&gt;</span> <span class="n">yGm</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">extern</span> <span class="s">&#34;C&#34;</span> <span class="n">__global__</span> <span class="n">__aicore__</span> <span class="kt">void</span> <span class="n">sinh_custom</span><span class="p">(</span><span class="n">GM_ADDR</span> <span class="n">x</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">y</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">GM_ADDR</span> <span class="n">tiling</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">GET_TILING_DATA</span><span class="p">(</span><span class="n">tiling_data</span><span class="p">,</span> <span class="n">tiling</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">KernelSinh</span> <span class="n">op</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">op</span><span class="p">.</span><span class="n">Init</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="n">op</span><span class="p">.</span><span class="n">Process</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="算子编译部署">算子编译部署</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># cd进入算子工程目录内</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 编译</span>
</span></span><span class="line"><span class="cl"><span class="c1"># chmod +x ./build.sh # 若没有执行权限，可以使用</span>
</span></span><span class="line"><span class="cl">./build.sh
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 部署</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> ./build_out
</span></span><span class="line"><span class="cl">./custom_opp_ubuntu_aarch64.run
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="算子测试">算子测试</h4>
<p>使用<code>samples</code>仓中<code>AddCustom</code>算子下的<code>AclNNInvocation</code>工程经过修改之后，进行测试。</p>
<h5 id="scriptsgen_datapy"><code>scripts/gen_data.py</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/python3</span>
</span></span><span class="line"><span class="cl"><span class="c1"># -*- coding:utf-8 -*-</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Copyright 2022-2023 Huawei Technologies Co., Ltd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">gen_golden_data_simple</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">golden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sinh</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">input_x</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="s2">&#34;./input/input_x.bin&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">golden</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="s2">&#34;./output/golden.bin&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">gen_golden_data_simple</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="srcmaincpp"><code>src/main.cpp</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">* @file main.cpp
</span></span></span><span class="line"><span class="cl"><span class="cm">*
</span></span></span><span class="line"><span class="cl"><span class="cm">* Copyright (C) 2023. Huawei Technologies Co., Ltd. All rights reserved.
</span></span></span><span class="line"><span class="cl"><span class="cm">*
</span></span></span><span class="line"><span class="cl"><span class="cm">* This program is distributed in the hope that it will be useful,
</span></span></span><span class="line"><span class="cl"><span class="cm">* but WITHOUT ANY WARRANTY; without even the implied warranty of
</span></span></span><span class="line"><span class="cl"><span class="cm">* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</span></span></span><span class="line"><span class="cl"><span class="cm">*/</span>
</span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;cstdint&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;sys/types.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;sys/stat.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;acl/acl.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;op_runner.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;common.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="n">g_isDevice</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">deviceId</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">OperatorDesc</span> <span class="nf">CreateOpDesc</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// define operator
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">shape</span> <span class="p">{</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span> <span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="n">aclDataType</span> <span class="n">dataType</span> <span class="o">=</span> <span class="n">ACL_FLOAT16</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">aclFormat</span> <span class="n">format</span> <span class="o">=</span> <span class="n">ACL_FORMAT_ND</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">OperatorDesc</span> <span class="n">opDesc</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">opDesc</span><span class="p">.</span><span class="n">AddInputTensorDesc</span><span class="p">(</span><span class="n">dataType</span><span class="p">,</span> <span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">shape</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">format</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">opDesc</span><span class="p">.</span><span class="n">AddOutputTensorDesc</span><span class="p">(</span><span class="n">dataType</span><span class="p">,</span> <span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">shape</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">format</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">opDesc</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">SetInputData</span><span class="p">(</span><span class="n">OpRunner</span> <span class="o">&amp;</span><span class="n">runner</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">size_t</span> <span class="n">fileSize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">ReadFile</span><span class="p">(</span><span class="s">&#34;../input/input_x.bin&#34;</span><span class="p">,</span> <span class="n">fileSize</span><span class="p">,</span> <span class="n">runner</span><span class="p">.</span><span class="n">GetInputBuffer</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">runner</span><span class="p">.</span><span class="n">GetInputSize</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Set input success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">ProcessOutputData</span><span class="p">(</span><span class="n">OpRunner</span> <span class="o">&amp;</span><span class="n">runner</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">WriteFile</span><span class="p">(</span><span class="s">&#34;../output/output_z.bin&#34;</span><span class="p">,</span> <span class="n">runner</span><span class="p">.</span><span class="n">GetOutputBuffer</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">runner</span><span class="p">.</span><span class="n">GetOutputSize</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Write output success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">DestoryResource</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">flag</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">aclrtResetDevice</span><span class="p">(</span><span class="n">deviceId</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Reset device %d failed&#34;</span><span class="p">,</span> <span class="n">deviceId</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">flag</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Reset Device success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">aclFinalize</span><span class="p">()</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Finalize acl failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">flag</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">flag</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Destory resource failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Destory resource success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">InitResource</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">output</span> <span class="o">=</span> <span class="s">&#34;../output&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">access</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">mkdir</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="mo">0700</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Make output directory successfully&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Make output directory fail&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// acl.json is dump or profiling config file
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">aclInit</span><span class="p">(</span><span class="s">&#34;../scripts/acl.json&#34;</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;acl init failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">aclrtSetDevice</span><span class="p">(</span><span class="n">deviceId</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Set device failed. deviceId is %d&#34;</span><span class="p">,</span> <span class="n">deviceId</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclFinalize</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Set device[%d] success&#34;</span><span class="p">,</span> <span class="n">deviceId</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// runMode is ACL_HOST which represents app is running in host
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// runMode is ACL_DEVICE which represents app is running in device
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">aclrtRunMode</span> <span class="n">runMode</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">aclrtGetRunMode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">runMode</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Get run mode failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">DestoryResource</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">g_isDevice</span> <span class="o">=</span> <span class="p">(</span><span class="n">runMode</span> <span class="o">==</span> <span class="n">ACL_DEVICE</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Get RunMode[%d] success&#34;</span><span class="p">,</span> <span class="n">runMode</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">RunOp</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// create op desc
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">OperatorDesc</span> <span class="n">opDesc</span> <span class="o">=</span> <span class="n">CreateOpDesc</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// create Runner
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">OpRunner</span> <span class="n">opRunner</span><span class="p">(</span><span class="o">&amp;</span><span class="n">opDesc</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">opRunner</span><span class="p">.</span><span class="n">Init</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Init OpRunner failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Load inputs
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">SetInputData</span><span class="p">(</span><span class="n">opRunner</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Set input data failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Run op
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">opRunner</span><span class="p">.</span><span class="n">RunOp</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Run op failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// process output data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">ProcessOutputData</span><span class="p">(</span><span class="n">opRunner</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Process output data failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Run op success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">InitResource</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Init resource failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">FAILED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Init resource success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">RunOp</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">DestoryResource</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">FAILED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">DestoryResource</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">SUCCESS</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="srcop_runnercpp"><code>src/op_runner.cpp</code></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span><span class="lnt">260
</span><span class="lnt">261
</span><span class="lnt">262
</span><span class="lnt">263
</span><span class="lnt">264
</span><span class="lnt">265
</span><span class="lnt">266
</span><span class="lnt">267
</span><span class="lnt">268
</span><span class="lnt">269
</span><span class="lnt">270
</span><span class="lnt">271
</span><span class="lnt">272
</span><span class="lnt">273
</span><span class="lnt">274
</span><span class="lnt">275
</span><span class="lnt">276
</span><span class="lnt">277
</span><span class="lnt">278
</span><span class="lnt">279
</span><span class="lnt">280
</span><span class="lnt">281
</span><span class="lnt">282
</span><span class="lnt">283
</span><span class="lnt">284
</span><span class="lnt">285
</span><span class="lnt">286
</span><span class="lnt">287
</span><span class="lnt">288
</span><span class="lnt">289
</span><span class="lnt">290
</span><span class="lnt">291
</span><span class="lnt">292
</span><span class="lnt">293
</span><span class="lnt">294
</span><span class="lnt">295
</span><span class="lnt">296
</span><span class="lnt">297
</span><span class="lnt">298
</span><span class="lnt">299
</span><span class="lnt">300
</span><span class="lnt">301
</span><span class="lnt">302
</span><span class="lnt">303
</span><span class="lnt">304
</span><span class="lnt">305
</span><span class="lnt">306
</span><span class="lnt">307
</span><span class="lnt">308
</span><span class="lnt">309
</span><span class="lnt">310
</span><span class="lnt">311
</span><span class="lnt">312
</span><span class="lnt">313
</span><span class="lnt">314
</span><span class="lnt">315
</span><span class="lnt">316
</span><span class="lnt">317
</span><span class="lnt">318
</span><span class="lnt">319
</span><span class="lnt">320
</span><span class="lnt">321
</span><span class="lnt">322
</span><span class="lnt">323
</span><span class="lnt">324
</span><span class="lnt">325
</span><span class="lnt">326
</span><span class="lnt">327
</span><span class="lnt">328
</span><span class="lnt">329
</span><span class="lnt">330
</span><span class="lnt">331
</span><span class="lnt">332
</span><span class="lnt">333
</span><span class="lnt">334
</span><span class="lnt">335
</span><span class="lnt">336
</span><span class="lnt">337
</span><span class="lnt">338
</span><span class="lnt">339
</span><span class="lnt">340
</span><span class="lnt">341
</span><span class="lnt">342
</span><span class="lnt">343
</span><span class="lnt">344
</span><span class="lnt">345
</span><span class="lnt">346
</span><span class="lnt">347
</span><span class="lnt">348
</span><span class="lnt">349
</span><span class="lnt">350
</span><span class="lnt">351
</span><span class="lnt">352
</span><span class="lnt">353
</span><span class="lnt">354
</span><span class="lnt">355
</span><span class="lnt">356
</span><span class="lnt">357
</span><span class="lnt">358
</span><span class="lnt">359
</span><span class="lnt">360
</span><span class="lnt">361
</span><span class="lnt">362
</span><span class="lnt">363
</span><span class="lnt">364
</span><span class="lnt">365
</span><span class="lnt">366
</span><span class="lnt">367
</span><span class="lnt">368
</span><span class="lnt">369
</span><span class="lnt">370
</span><span class="lnt">371
</span><span class="lnt">372
</span><span class="lnt">373
</span><span class="lnt">374
</span><span class="lnt">375
</span><span class="lnt">376
</span><span class="lnt">377
</span><span class="lnt">378
</span><span class="lnt">379
</span><span class="lnt">380
</span><span class="lnt">381
</span><span class="lnt">382
</span><span class="lnt">383
</span><span class="lnt">384
</span><span class="lnt">385
</span><span class="lnt">386
</span><span class="lnt">387
</span><span class="lnt">388
</span><span class="lnt">389
</span><span class="lnt">390
</span><span class="lnt">391
</span><span class="lnt">392
</span><span class="lnt">393
</span><span class="lnt">394
</span><span class="lnt">395
</span><span class="lnt">396
</span><span class="lnt">397
</span><span class="lnt">398
</span><span class="lnt">399
</span><span class="lnt">400
</span><span class="lnt">401
</span><span class="lnt">402
</span><span class="lnt">403
</span><span class="lnt">404
</span><span class="lnt">405
</span><span class="lnt">406
</span><span class="lnt">407
</span><span class="lnt">408
</span><span class="lnt">409
</span><span class="lnt">410
</span><span class="lnt">411
</span><span class="lnt">412
</span><span class="lnt">413
</span><span class="lnt">414
</span><span class="lnt">415
</span><span class="lnt">416
</span><span class="lnt">417
</span><span class="lnt">418
</span><span class="lnt">419
</span><span class="lnt">420
</span><span class="lnt">421
</span><span class="lnt">422
</span><span class="lnt">423
</span><span class="lnt">424
</span><span class="lnt">425
</span><span class="lnt">426
</span><span class="lnt">427
</span><span class="lnt">428
</span><span class="lnt">429
</span><span class="lnt">430
</span><span class="lnt">431
</span><span class="lnt">432
</span><span class="lnt">433
</span><span class="lnt">434
</span><span class="lnt">435
</span><span class="lnt">436
</span><span class="lnt">437
</span><span class="lnt">438
</span><span class="lnt">439
</span><span class="lnt">440
</span><span class="lnt">441
</span><span class="lnt">442
</span><span class="lnt">443
</span><span class="lnt">444
</span><span class="lnt">445
</span><span class="lnt">446
</span><span class="lnt">447
</span><span class="lnt">448
</span><span class="lnt">449
</span><span class="lnt">450
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">* @file op_runner.cpp
</span></span></span><span class="line"><span class="cl"><span class="cm">*
</span></span></span><span class="line"><span class="cl"><span class="cm">* Copyright (C) 2020. Huawei Technologies Co., Ltd. All rights reserved.
</span></span></span><span class="line"><span class="cl"><span class="cm">*
</span></span></span><span class="line"><span class="cl"><span class="cm">* This program is distributed in the hope that it will be useful,
</span></span></span><span class="line"><span class="cl"><span class="cm">* but WITHOUT ANY WARRANTY; without even the implied warranty of
</span></span></span><span class="line"><span class="cl"><span class="cm">* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</span></span></span><span class="line"><span class="cl"><span class="cm">*/</span>
</span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;op_runner.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;aclnn_sinh_custom.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;limits&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;cassert&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;acl/acl_op_compiler.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;common.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">extern</span> <span class="kt">bool</span> <span class="n">g_isDevice</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">OpRunner</span><span class="o">::</span><span class="n">OpRunner</span><span class="p">(</span><span class="n">OperatorDesc</span> <span class="o">*</span><span class="n">opDesc</span><span class="p">)</span> <span class="o">:</span> <span class="n">opDesc_</span><span class="p">(</span><span class="n">opDesc</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">numInputs_</span> <span class="o">=</span> <span class="n">opDesc</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">numOutputs_</span> <span class="o">=</span> <span class="n">opDesc</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">OpRunner</span><span class="o">::~</span><span class="n">OpRunner</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numInputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclDestroyTensor</span><span class="p">(</span><span class="n">inputTensor_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclDestroyDataBuffer</span><span class="p">(</span><span class="n">inputBuffers_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFree</span><span class="p">(</span><span class="n">devInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFree</span><span class="p">(</span><span class="n">hostInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFreeHost</span><span class="p">(</span><span class="n">hostInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numOutputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclDestroyTensor</span><span class="p">(</span><span class="n">outputTensor_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclDestroyDataBuffer</span><span class="p">(</span><span class="n">outputBuffers_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFree</span><span class="p">(</span><span class="n">devOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFree</span><span class="p">(</span><span class="n">hostOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtFreeHost</span><span class="p">(</span><span class="n">hostOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">Init</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numInputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">auto</span> <span class="n">size</span> <span class="o">=</span> <span class="n">GetInputSize</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="kt">void</span> <span class="o">*</span><span class="n">devMem</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">devMem</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">ACL_MEM_MALLOC_NORMAL_ONLY</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">devInputs_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devMem</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputBuffers_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">aclCreateDataBuffer</span><span class="p">(</span><span class="n">devMem</span><span class="p">,</span> <span class="n">size</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kt">void</span> <span class="o">*</span><span class="n">hostInput</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostInput</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">ACL_MEM_MALLOC_NORMAL_ONLY</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostInput</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">hostInput</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc memory for input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">hostInputs_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">hostInput</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">aclTensor</span> <span class="o">*</span><span class="n">inputTensor</span> <span class="o">=</span> <span class="n">aclCreateTensor</span><span class="p">(</span><span class="n">GetInputShape</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">data</span><span class="p">(),</span> <span class="n">GetInputNumDims</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">GetInputDataType</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="k">nullptr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">GetInputFormat</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">GetInputShape</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">data</span><span class="p">(),</span> <span class="n">GetInputNumDims</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">devInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">inputTensor</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Create Tensor for input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputTensor_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">inputTensor</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numOutputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">auto</span> <span class="n">size</span> <span class="o">=</span> <span class="n">GetOutputSize</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="kt">void</span> <span class="o">*</span><span class="n">devMem</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">devMem</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">ACL_MEM_MALLOC_NORMAL_ONLY</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for output[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">devOutputs_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devMem</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputBuffers_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">aclCreateDataBuffer</span><span class="p">(</span><span class="n">devMem</span><span class="p">,</span> <span class="n">size</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kt">void</span> <span class="o">*</span><span class="n">hostOutput</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostOutput</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">ACL_MEM_MALLOC_NORMAL_ONLY</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for output[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostOutput</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory for output[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">hostOutput</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc host memory for output[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">hostOutputs_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">hostOutput</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">aclTensor</span> <span class="o">*</span><span class="n">outputTensor</span> <span class="o">=</span> <span class="n">aclCreateTensor</span><span class="p">(</span><span class="n">GetOutputShape</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">data</span><span class="p">(),</span> <span class="n">GetOutputNumDims</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">GetOutputDataType</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="k">nullptr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">GetOutputFormat</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">GetOutputShape</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">data</span><span class="p">(),</span> <span class="n">GetOutputNumDims</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">devOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">outputTensor</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Create Tensor for output[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputTensor_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">outputTensor</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">NumInputs</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">numInputs_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">NumOutputs</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">numOutputs_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputSize</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescSize</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputNumDims</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescNumDims</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">aclDataType</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputDataType</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ACL_DT_UNDEFINED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescType</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">aclFormat</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputFormat</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ACL_FORMAT_UNDEFINED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescFormat</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputShape</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">aclGetTensorDescNumDims</span><span class="p">(</span><span class="n">desc</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int64_t</span> <span class="n">dimSize</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclGetTensorDescDimV2</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">dimSize</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;get dims from tensor desc failed. dims index = %zu&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="n">ret</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">ret</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">dimSize</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputSize</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescSize</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputNumDims</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescNumDims</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">aclDataType</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputDataType</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ACL_DT_UNDEFINED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescType</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">aclFormat</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputFormat</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ACL_FORMAT_UNDEFINED</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescFormat</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputShape</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">aclGetTensorDescNumDims</span><span class="p">(</span><span class="n">desc</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int64_t</span> <span class="n">dimSize</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclGetTensorDescDimV2</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">dimSize</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;get dims from tensor desc failed. dims index = %zu&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="n">ret</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">ret</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">dimSize</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetInputElementCount</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numInputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescElementCount</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">size_t</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">GetOutputElementCount</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nf">aclGetTensorDescElementCount</span><span class="p">(</span><span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">bool</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">RunOp</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numInputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">auto</span> <span class="n">size</span> <span class="o">=</span> <span class="n">GetInputSize</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">aclrtMemcpyKind</span> <span class="n">kind</span> <span class="o">=</span> <span class="n">ACL_MEMCPY_HOST_TO_DEVICE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">kind</span> <span class="o">=</span> <span class="n">ACL_MEMCPY_DEVICE_TO_DEVICE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMemcpy</span><span class="p">(</span><span class="n">devInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">size</span><span class="p">,</span> <span class="n">hostInputs_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">size</span><span class="p">,</span> <span class="n">kind</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Copy input[%zu] failed&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Copy input[%zu] success&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">aclrtStream</span> <span class="n">stream</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">aclrtCreateStream</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Create stream failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Create stream success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">size_t</span> <span class="n">workspaceSize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">aclOpExecutor</span> <span class="o">*</span><span class="n">handle</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//添加计算workspace大小并申请内存代码
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">auto</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">aclnnSinhCustomGetWorkspaceSize</span><span class="p">(</span><span class="n">inputTensor_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outputTensor_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                              <span class="o">&amp;</span><span class="n">workspaceSize</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">handle</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtDestroyStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Get Operator Workspace failed. error code is %d&#34;</span><span class="p">,</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ret</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="o">*</span><span class="n">workspace</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">workspaceSize</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">workspace</span><span class="p">,</span> <span class="n">workspaceSize</span><span class="p">,</span> <span class="n">ACL_MEM_MALLOC_NORMAL_ONLY</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Malloc device memory failed&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//添加执行算子代码
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">aclnnSinhCustom</span><span class="p">(</span><span class="n">workspace</span><span class="p">,</span> <span class="n">workspaceSize</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtDestroyStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Execute Operator failed. error code is %d&#34;</span><span class="p">,</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ret</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">ret</span> <span class="o">=</span> <span class="n">aclrtSynchronizeStreamWithTimeout</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="mi">5000</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="n">SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Synchronize stream failed. error code is %d&#34;</span><span class="p">,</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ret</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtDestroyStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Synchronize stream success&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numOutputs_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">auto</span> <span class="n">size</span> <span class="o">=</span> <span class="n">GetOutputSize</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">aclrtMemcpyKind</span> <span class="n">kind</span> <span class="o">=</span> <span class="n">ACL_MEMCPY_DEVICE_TO_HOST</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">g_isDevice</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">kind</span> <span class="o">=</span> <span class="n">ACL_MEMCPY_DEVICE_TO_DEVICE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">aclrtMemcpy</span><span class="p">(</span><span class="n">hostOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">size</span><span class="p">,</span> <span class="n">devOutputs_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">size</span><span class="p">,</span> <span class="n">kind</span><span class="p">)</span> <span class="o">!=</span> <span class="n">ACL_SUCCESS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Copy output[%zu] success&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtDestroyStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">INFO_LOG</span><span class="p">(</span><span class="s">&#34;Copy output[%zu] success&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="n">aclrtDestroyStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">DoPrintData</span><span class="p">(</span><span class="k">const</span> <span class="n">T</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">count</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">elementsPerRow</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">elementsPerRow</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">count</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">setw</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="n">elementsPerRow</span> <span class="o">==</span> <span class="n">elementsPerRow</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">DoPrintFp16Data</span><span class="p">(</span><span class="k">const</span> <span class="n">aclFloat16</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">count</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">elementsPerRow</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">elementsPerRow</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">count</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">setw</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">setprecision</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">aclFloat16ToFloat</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="n">elementsPerRow</span> <span class="o">==</span> <span class="n">elementsPerRow</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">PrintData</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">count</span><span class="p">,</span> <span class="n">aclDataType</span> <span class="n">dataType</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">elementsPerRow</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">data</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Print data failed. data is nullptr&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">switch</span> <span class="p">(</span><span class="n">dataType</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_BOOL</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">bool</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_INT8</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">int8_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_UINT8</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">uint8_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_INT16</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">int16_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_UINT16</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">uint16_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_INT32</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">int32_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_UINT32</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">uint32_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_INT64</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">int64_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_UINT64</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">uint64_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_FLOAT16</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintFp16Data</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">aclFloat16</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_FLOAT</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">case</span> <span class="nl">ACL_DOUBLE</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">DoPrintData</span><span class="p">(</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">double</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">count</span><span class="p">,</span> <span class="n">elementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">default</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;Unsupported type: %d&#34;</span><span class="p">,</span> <span class="n">dataType</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">PrintInput</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">numElementsPerRow</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numInputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numInputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">inputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="n">PrintData</span><span class="p">(</span><span class="n">hostInputs_</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">GetInputElementCount</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">aclGetTensorDescType</span><span class="p">(</span><span class="n">desc</span><span class="p">),</span> <span class="n">numElementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">OpRunner</span><span class="o">::</span><span class="n">PrintOutput</span><span class="p">(</span><span class="n">size_t</span> <span class="n">index</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">numElementsPerRow</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">numOutputs_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">ERROR_LOG</span><span class="p">(</span><span class="s">&#34;index out of range. index = %zu, numOutputs = %zu&#34;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">numOutputs_</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">opDesc_</span><span class="o">-&gt;</span><span class="n">outputDesc</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="n">PrintData</span><span class="p">(</span><span class="n">hostOutputs_</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">GetOutputElementCount</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">aclGetTensorDescType</span><span class="p">(</span><span class="n">desc</span><span class="p">),</span> <span class="n">numElementsPerRow</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="对部署的算子进行测试">对部署的算子进行测试</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">bash run.sh
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="过程注意点">过程注意点</h3>
<ol>
<li>
<p>在使用<code>msopgen</code>工具(<code>mindspore op generator</code>)生成算子工程时，<code>soc_version</code>要设置为<code>Ascend310B</code>，而不是<code>Ascend310B4</code>。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">bash
</span></span><span class="line"><span class="cl">复制代码
</span></span><span class="line"><span class="cl">${INSTALL_DIR}/python/site-packages/bin/msopgen gen -i sinh.json -c ai_core-Ascend310B -lan cpp -out Sinh
</span></span></code></pre></td></tr></table>
</div>
</div><p>官方文档-msopgen生成自定义算子工程</p>
</li>
<li>
<p>算子工程不要通过<code>cp</code>复制，需要使用<code>msopgen</code>根据<code>json</code>文件生成。</p>
</li>
<li>
<p>初始化生成的算子工程，需要修改文件<code>CMakePresets.json</code>编译配置项中的<code>ASCEND_CANN_PACKAGE_PATH</code>为CANN软件包安装后的实际路径。</p>
</li>
<li>
<p>SinhCustom算子配置文件内容如下:</p>
</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;op&#34;</span><span class="p">:</span> <span class="s2">&#34;SinhCustom&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;language&#34;</span><span class="p">:</span><span class="s2">&#34;cpp&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;input_desc&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;x&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;param_type&#34;</span><span class="p">:</span> <span class="s2">&#34;required&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;format&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;ND&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;fp16&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;output_desc&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;y&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;param_type&#34;</span><span class="p">:</span> <span class="s2">&#34;required&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;format&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;ND&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;fp16&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-07-11</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/huaweishengteng/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记" data-hashtags="website"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-hashtag="website"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记" data-ralateuid="6086629393"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记" data-description=""><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记" data-description=""><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="https://wangyudong.netlify.app/huaweishengteng/" data-title="Ascend C算子 学习笔记"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/website/">Website</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/awards/" class="prev" rel="prev" title="学术成果"><i class="fas fa-angle-left fa-fw"></i>学术成果</a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=424&t=tt&d=o_3r5JGQyri9esND225b2wSMsyUgYerHhwL58eRwQG0&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script><div class="footer-line"><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Dong</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/mermaid/mermaid.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/valine/Valine.min.js"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/mermaid/mermaid.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{"valine":{"appId":"ndzXwOy58BYrhDPC7eTav7HP-gzGzoHsz","appKey":"SL9ydCelSxirpnPfFitBbCuB","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@5.0.1/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"en","pageSize":10,"placeholder":"Your comment ...","recordIP":true,"visitor":true}},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"id-1":"\r\n  graph LR;\r\n      subgraph Ascend C SPMD Model\r\n      A[输入数据] --\u003e|切分| B[数据分片1]\r\n      A --\u003e|切分| C[数据分片2]\r\n      A --\u003e|切分| D[数据分片3]\r\n      B --\u003e T1[任务T1] --\u003e T2[任务T2] --\u003e T3[任务T3] --\u003e E[输出数据分片1]\r\n      C --\u003e T4[任务T1] --\u003e T5[任务T2] --\u003e T6[任务T3] --\u003e F[输出数据分片2]\r\n      D --\u003e T7[任务T1] --\u003e T8[任务T2] --\u003e T9[任务T3] --\u003e G[输出数据分片3]\r\n      end\r\n      E --\u003e H[合并输出数据]\r\n      F --\u003e H\r\n      G --\u003e H\r","id-2":"\r\ngraph TD;\r\n    A[生成算子工程] --\u003e B[修改配置文件]\r\n    B --\u003e C[实现 `op_host/sinh_custom_tiling.h`]\r\n    C --\u003e D[实现 `op_host/sinh_custom.cpp`]\r\n    D --\u003e E[实现 `op_kernel/sinh_custom.cpp`]\r\n    E --\u003e F[编译算子]\r\n    F --\u003e G[部署算子]\r\n    G --\u003e H[测试算子]\r"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript" charset="utf-8"  src="https://cdn.jsdelivr.net/npm/live2d-widget@3.1.4/lib/L2Dwidget.min.js"></script>

<script type="text/javascript">
    L2Dwidget.init({
        model: {
            scale: 1,
            hHeadPos: 0.5,
            vHeadPos: 0.618,
            
            
            
            
            jsonPath: 'https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json'
        },
        display: {
            superSample: 1,     
            width: 120,         
            height: 300,        
            position: 'left',   
            hOffset: 0,         
            vOffset: 0,         
        },
        mobile: {
            show: false,         
            scale: 0.3,           
            motion: true,       
        },
        react: {
            opacityDefault: 1,  
            opacityOnHover: 1,  
        },
     });
</script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/jquery@2.1.3/dist/jquery.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

<script type="text/javascript" src="/js/custom.js"></script></body>
</html>
